}
cv.glm(data = Boston,
glmfit = model_full,
cost = MAE_cost,
K = 10)$delta[2]
cv.glm(data = Boston,
glmfit = model_full,
cost = MSE_cost,
K = 10)$delta[2]
cv.glm(data = Boston,
glmfit = model_2var,
cost = MSE_cost,
K = 10)$delta[2]
return(mean((y - yhat)^2))
MSE_cost <- function(y, yhat){
return(mean((y - yhat)^2))
}
cv.glm(data = Boston,
glmfit = model_full,
cost = MSE_cost,
K = 10)$delta[2]
cv.glm(data = Boston,
glmfit = model_2var,
cost = MSE_cost,
K = 10)$delta[2]
#install.packages("glmnet")
library(glmnet)
Boston
Boston[, -c('medv')]
names(Boston)
names(Boston)=='medv'
names(Boston)!='medv'
Boston[, names(Boston)!='medv']
as.matrix(Boston[, names(Boston)!='medv'])
#use 10-fold cross validation to pick lambda
cv_lasso_fit = cv.glmnet(x = as.matrix(Boston[, names(Boston)!='medv']),
y = Boston$medv,
alpha = 1,
nfolds = 10)
plot(cv_lasso_fit)
cv_lasso_fit$lambda.min
coef(lasso_fit, s = cv_lasso_fit$lambda.min)
lasso_fit  <- glmnet(x = as.matrix(Boston[, names(Boston)!='medv']),
y = Boston$medv,
alpha = 1)
coef(lasso_fit, s = cv_lasso_fit$lambda.min)
pred_IS <- predict(lasso_fit,
as.matrix(Boston[, names(Boston)=='medv']),
s = cv_lasso_fit$lambda.min)
pred_IS <- predict(lasso_fit,
as.matrix(Boston[, names(Boston)!='medv']),
s = cv_lasso_fit$lambda.min)
MAE_cost(pred_IS, Boston$medv)
pred_IS
plot(pred_IS, Boston$medv)
abline(a = 0, b = 1)
plot(pred_IS, Boston$medv)
abline(a = 0, b = 1)
plot(pred_IS, Boston$medv)
abline(a = 0, b = 1)
MSE_cost(pred_IS, Boston$medv)
MAE_cost(pred_IS, Boston$medv)
MAE_cost <- function(y, yhat){
return(mean(abs(y - yhat)))
}
cv.glm(data = Boston,
glmfit = model_full,
cost = MAE_cost,
K = 10)$delta[2]
cv.glm(data = Boston,
glmfit = model_2var,
cost = MAE_cost,
K = 10)$delta[2]
MSE_cost <- function(y, yhat){
return(mean((y - yhat)^2))
}
cv.glm(data = Boston,
glmfit = model_full,
cost = MSE_cost,
K = 10)$delta[2]
cv.glm(data = Boston,
glmfit = model_2var,
cost = MSE_cost,
K = 10)$delta[2]
MSE_cost(pred_IS, Boston$medv)
MAE_cost(pred_IS, Boston$medv)
#install.packages("glmnet")
library(glmnet)
lasso_fit  <- glmnet(x = as.matrix(Boston[, names(Boston)!='medv']),
y = Boston$medv,
alpha = 1)
#use 10-fold cross validation to pick lambda
cv_lasso_fit = cv.glmnet(x = as.matrix(Boston[, names(Boston)!='medv']),
y = Boston$medv,
alpha = 1,
nfolds = 10)
plot(cv_lasso_fit)
cv_lasso_fit
plot(cv_lasso_fit)
pcut = 0.5
getwd()
library(tidyverse)
credit = read_csv("data/credit_default.csv")
names(credit)
mean(credit$default)
credit_glm = glm(default ~ PAY_0,
family = binomial,
data = credit)
credit_prob = fitted(credit_glm)
plot(credit$PAY_0, credit$default)
points(credit$PAY_0, credit_prob)
plot(credit$PAY_0, credit$default)
points(credit$PAY_0, credit_prob)
credit$default
mean(credit$default)
reticulate::repl_python()
boston_data <- data(Boston)
library(MASS) #this data is in MASS package
boston_data <- data(Boston)
sample_index <- sample(nrow(Boston),nrow(Boston)*0.90)
boston_train <- Boston[sample_index,]
boston_test <- Boston[-sample_index,]
library(rpart)
library(rpart.plot)
install.packages('rpart.plot')
library(rpart.plot)
boston_rpart <- rpart(formula = medv ~ .,
data = boston_train)
boston_rpart
prp(boston_rpart,digits = 4, extra = 1)
boston_train_pred_tree = predict(boston_rpart)
boston_test_pred_tree = predict(boston_rpar,
boston_test)
boston_train_pred_tree = predict(boston_rpart)
boston_test_pred_tree = predict(boston_rpart,
boston_test)
boston_train_pred_tree
mean((boston_train_pred_tree - boston_test$medv)^2)
mean((boston_train_pred_tree - boston_test$medv)^2)
mean((boston_test_pred_tree - boston_test$medv)^2)
mean((boston_train_pred_tree - boston_train$medv)^2)
mean((boston_test_pred_tree - boston_test$medv)^2)
boston_reg = lm(medv~., data = boston_train)
boston_test_pred_reg = predict(boston_reg,
boston_test)
mean((boston_test_pred_reg - boston_test$medv)^2)
credit_data <- read.csv(file = "https://yanyudm.github.io/Data-Mining-R/lecture/data/credit_default.csv", header=T)
library(dplyr)
credit_data<- rename(credit_data, default=default.payment.next.month)
# convert categorical data to factor
credit_data$SEX<- as.factor(credit_data$SEX)
credit_data$EDUCATION<- as.factor(credit_data$EDUCATION)
credit_data$MARRIAGE<- as.factor(credit_data$MARRIAGE)
index <- sample(nrow(credit_data),
nrow(credit_data)*0.80)
credit_train = credit_data[index,]
credit_test = credit_data[-index,]
# convert categorical data to factor
credit_data$SEX<- as.factor(credit_data$SEX)
credit_data$EDUCATION<- as.factor(credit_data$EDUCATION)
credit_data$MARRIAGE<- as.factor(credit_data$MARRIAGE)
index <- sample(nrow(credit_data),
nrow(credit_data)*0.80)
credit_train = credit_data[index,]
credit_test = credit_data[-index,]
credit_rpart0 <- rpart(formula = default ~ .,
data = credit_train,
method = "class")
credit_rpart <- rpart(formula = default ~ .,
data = credit_train,
method = "class",
parms = list(loss=matrix(c(0,5,1,0),
nrow = 2)))
pred0 <- predict(credit_rpart0, type="class")
table(credit_train$default, pred0, dnn = c("True", "Pred"))
credit_rpart <- rpart(formula = default ~ . ,
data = credit_train,
method = "class",
parms = list(loss=matrix(c(0,5,1,0), nrow = 2)))
credit_rpart
prp(credit_rpart, extra = 1)
credit_train_pred_tree1<- predict(credit_rpart,
credit_train,
type="class")
table(credit_train$default,
credit_train_pred_tree1,
dnn=c("Truth","Predicted"))
pcut <- weight0/(weight1+weight0)
cost <- function(r, phat){
weight1 <- 5
weight0 <- 1
pcut <- weight0/(weight1+weight0)
c1 <- (r==1)&(phat<pcut) #logical vector - true if actual 1 but predict 0
c0 <-(r==0)&(phat>pcut) #logical vector - true if actual 0 but predict 1
return(mean(weight1*c1+weight0*c0))
}
head(predict(credit_rpart,
credit_test,
type="prob"))
cost(credit_train$default,
predict(credit_rpart,
credit_train,
type="prob")[,2])
cost(credit_train$default,
predict(credit_rpart,
credit_train,
type="prob")[,2])
cost(credit_test$default,
predict(credit_rpart,
credit_test,
type="prob")[,2])
#Fit logistic regression model
credit_glm <- glm(default~.,
data = credit_train,
family=binomial)
#Get binary prediction
credit_test_pred_glm <- predict(credit_glm, credit_test, type="response")
#Get binary prediction
credit_test_pred_glm <- predict(credit_glm,
credit_test,
type="response")
#Calculate cost using test set
cost(credit_test$default, credit_test_pred_glm)
#Calculate cost using test set
cost(credit_test$default,
credit_test_pred_glm)
table(credit_test$default,
as.numeric(credit_test_pred_glm>1/6),
dnn=c("Truth","Predicted"))
credit_rpart <- rpart(formula = default ~ .,
data = credit_train,
method = "class",
parms = list(loss=matrix(c(0,5,1,0), nrow = 2)))
#Probability of getting 1
credit_test_prob_rpart = predict(credit_rpart,
credit_test,
type="prob")
#install.packages('ROCR')
library(ROCR)
pred = prediction(credit_test_prob_rpart[,2],
credit_test$default)
perf = performance(pred, "tpr", "fpr")
plot(perf, colorize=TRUE)
credit_test_pred_rpart = as.numeric(credit_test_prob_rpart[,2] > 1/(5+1))
table(credit_test$default,
credit_test_pred_rpart,
dnn=c("Truth","Predicted"))
credit_rpart <- rpart(formula = default ~ .,
data = credit_train,
method = "class",
parms = list(loss=matrix(c(0,5,1,0), nrow = 2)))
pred <- predict(credit_rpart, type="class")
table(credit_train$default, pred, dnn = c("True", "Pred"))
credit_rpart0 <- rpart(formula = default ~ .,
data = credit_train,
method = "class")
pred0 <- predict(credit_rpart0, type="class")
table(credit_train$default, pred0, dnn = c("True", "Pred"))
credit_train_pred_tree =
predict(credit_rpart,
credit_test,
type="prob")
credit_test_pred_tree =
predict(credit_rpart,
credit_test,
type="prob")
credit_train_pred_tree
credit_train_pred_tree =
predict(credit_rpart,
credit_test,
type="prob")
credit_test_pred_tree =
predict(credit_rpart,
credit_test,
type="prob")
cost(credit_train$default,
credit_train_pred_tree[,2])
cost(credit_test$default,
credit_test_pred_tree[,2])
credit_train_pred_tree =
predict(credit_rpart,
credit_test,
type="class")
credit_test_pred_tree =
predict(credit_rpart,
credit_test,
type="class")
table(credit_train$default,
credit_train_pred_tree,
dnn=c("Truth","Predicted"))
credit_train_pred_tree =
predict(credit_rpart,
credit_test,
type="class")
credit_test_pred_tree =
predict(credit_rpart,
credit_test,
type="class")
table(credit_train$default,
credit_train_pred_tree,
dnn=c("Truth","Predicted"))
credit_train_pred_tree
credit_train$default
table(credit_train$default,
credit_train_pred_tree,
dnn=c("Truth","Predicted"))
credit_train_pred_tree =
predict(credit_rpart,
credit_train,
type="class")
credit_test_pred_tree =
predict(credit_rpart,
credit_test,
type="class")
table(credit_train$default,
credit_train_pred_tree,
dnn=c("Truth","Predicted"))
table(credit_test$default,
credit_test_pred_tree,
dnn=c("Truth","Predicted"))
credit_train_prob_tree =
predict(credit_rpart,
credit_test,
type="prob")
credit_test_prob_tree =
predict(credit_rpart,
credit_test,
type="prob")
cost <- function(r, phat){
credit_train_prob_tree =
predict(credit_rpart,
credit_test,
type="prob")
credit_test_prob_tree =
predict(credit_rpart,
credit_test,
type="prob")
cost <- function(r, phat){
weight1 <- 5
weight0 <- 1
pcut <- weight0/(weight1+weight0)
c1 <- (r==1)&(phat<pcut) #logical vector - true if actual 1 but predict 0
c0 <-(r==0)&(phat>pcut) #logical vector - true if actual 0 but predict 1
return(mean(weight1*c1+weight0*c0))
}
cost(credit_train$default,
credit_train_prob_tree[,2])
credit_train_prob_tree =
predict(credit_rpart,
credit_test,
type="prob")
credit_test_prob_tree =
predict(credit_rpart,
credit_test,
type="prob")
cost <- function(r, phat){
weight1 <- 5
weight0 <- 1
pcut <- weight0/(weight1+weight0)
c1 <- (r==1)&(phat<pcut) #logical vector - true if actual 1 but predict 0
c0 <-(r==0)&(phat>pcut) #logical vector - true if actual 0 but predict 1
return(mean(weight1*c1+weight0*c0))
}
cost(credit_train$default,
credit_train_prob_tree[,2])
cost(credit_test$default,
credit_test_prob_tree[,2])
#Fit logistic regression model
credit_glm <- glm(default~.,
data = credit_train,
family=binomial)
credit_test_pred_glm <- predict(credit_glm,
credit_test,
type="response")
credit_test_pred_glm
#Calculate cost using test set
cost(credit_test$default,
credit_test_prob_glm)
#Get binary prediction
credit_test_prob_glm <- predict(credit_glm,
credit_test,
type="response")
#Calculate cost using test set
cost(credit_test$default,
credit_test_prob_glm)
table(credit_test$default,
(credit_test_prob_glm>1/6)*1,
dnn=c("Truth","Predicted"))
credit_rpart <- rpart(formula = default ~ .,
data = credit_train,
method = "class",
parms = list(loss=matrix(c(0,5,1,0), nrow = 2)))
#Probability of getting 1
credit_test_prob_rpart = predict(credit_rpart,
credit_test,
type="prob")
#install.packages('ROCR')
library(ROCR)
credit_test_prob_rpart
pred = prediction(credit_test_prob_rpart[,2],
credit_test$default)
perf = performance(pred, "tpr", "fpr")
plot(perf, colorize=TRUE)
credit_test_pred_rpart = 1*(credit_test_prob_rpart[,2] > 1/(5+1))
table(credit_test$default,
credit_test_pred_rpart,
dnn=c("Truth","Predicted"))
library(MASS) #this data is in MASS package
boston_data <- data(Boston)
sample_index <- sample(nrow(Boston),nrow(Boston)*0.90)
boston_train <- Boston[sample_index,]
boston_test <- Boston[-sample_index,]
library(rpart)
library(rpart.plot)
boston_rpart <- rpart(formula = medv ~ .,
data = boston_train)
boston_rpart
prp(boston_rpart,digits = 4, extra = 1)
boston_train_pred_tree = predict(boston_rpart,
boston_train)
boston_train_pred_tree
boston_train_pred_tree = predict(boston_rpart,
boston_train)
boston_test_pred_tree = predict(boston_rpart,
boston_test)
mean((boston_train_pred_tree - boston_train$medv)^2)
mean((boston_test_pred_tree - boston_test$medv)^2)
boston_data <- data(Boston)
boston_data
boston_data
library(MASS) #this data is in MASS package
sample_index <- sample(nrow(Boston),nrow(Boston)*0.90)
boston_train <- Boston[sample_index,]
boston_test <- Boston[-sample_index,]
#install.packages('rpart')
#install.packages('rpart.plot')
library(rpart)
boston_rpart <- rpart(formula = medv ~ .,
data = boston_train)
boston_rpart
prp(boston_rpart,digits = 4, extra = 1)
boston_train_pred_tree = predict(boston_rpart,
boston_train)
boston_test_pred_tree = predict(boston_rpart,
boston_test)
mean((boston_train_pred_tree - boston_train$medv)^2)
mean((boston_test_pred_tree - boston_test$medv)^2)
boston_reg = lm(medv ~ .,
data = boston_train)
boston_test_pred_reg = predict(boston_reg,
boston_test)
mean((boston_test_pred_reg - boston_test$medv)^2)
mean((boston_train$medv - mean(boston_train$medv))^2)
boston_pruned_tree = prune(boston_largetree, cp = 0.008)
boston_largetree <- rpart(formula = medv ~ .,
data = boston_train,
cp = 0.001)
prp(boston_largetree)
plotcp(boston_largetree)
boston_pruned_tree = prune(boston_largetree, cp = 0.008)
boston_largetree
boston_pruned_tree = prune(boston_largetree, cp = 0.008)
boston_pruned_tree
prp(boston_pruned_tree)
library(rpart)
library(rpart.plot)
library(dplyr)
credit_data <- read.csv(file = "https://yanyudm.github.io/Data-Mining-R/lecture/data/credit_default.csv", header=T)
credit_data<- rename(credit_data, default=default.payment.next.month)
# convert categorical data to factor
credit_data$SEX<- as.factor(credit_data$SEX)
credit_data$EDUCATION<- as.factor(credit_data$EDUCATION)
credit_data$MARRIAGE<- as.factor(credit_data$MARRIAGE)
index <- sample(nrow(credit_data),
nrow(credit_data)*0.80)
credit_train = credit_data[index,]
credit_test = credit_data[-index,]
credit_rpart_sym <- rpart(formula = default ~ .,
data = credit_train,
method = "class")
credit_rpart_sym
pred_sym <- predict(credit_rpart_sym, type="class")
table(credit_train$default,
pred_sym,
dnn = c("True", "Pred"))
crdit_rpart
credit_rpart <- rpart(formula = default ~ .,
data = credit_train,
method = "class",
parms = list(loss=matrix(c(0,5,1,0), nrow = 2)))
credit_rpart
pred <- predict(credit_rpart, type="class")
table(credit_train$default,
pred,
dnn = c("True", "Pred"))
prp(credit_rpart, extra = 1)
prp(credit_rpart)
prp(credit_rpart, extra = 1)
credit_train_pred_tree =
predict(credit_rpart,
credit_train,
type="class")
credit_test_pred_tree =
predict(credit_rpart,
credit_test,
type="class")
table(credit_train$default,
credit_train_pred_tree,
dnn=c("Truth","Predicted"))
table(credit_test$default,
credit_test_pred_tree,
dnn=c("Truth","Predicted"))
